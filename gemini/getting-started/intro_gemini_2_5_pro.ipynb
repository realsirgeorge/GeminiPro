{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realsirgeorge/GeminiPro/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqi5B7V_Rjim"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyPmicX9RlZX"
      },
      "source": [
        "# Intro to Gemini 2.5 Pro\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_2_5_pro.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MqT58L6Rm_q"
      },
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Eric Dong](https://github.com/gericdong) |\n",
        "| [Holt Skinner](https://github.com/holtskinner) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxnv1D5RoZw"
      },
      "source": [
        "## Overview\n",
        "\n",
        "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
        "\n",
        "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
        "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
        "</a>\n",
        "\n",
        "[Gemini 2.5 Pro](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro) is Google's most advanced reasoning Gemini model, to solve complex problems. With the 2.5 series, the Gemini models are now hybrid reasoning models! Gemini 2.5 Pro can apply an extended amount of thinking across tasks, and use tools in order to maximize response accuracy.\n",
        "\n",
        "Gemini 2.5 Pro is:\n",
        "\n",
        "- A significant improvement from previous models across capabilities including coding, reasoning, and multimodality\n",
        "- Industry-leading in reasoning with state of the art performance in Math & STEM benchmarks\n",
        "- An amazing model for code, with particularly strong web development\n",
        "- Particularly good for complex prompts, while still being well rounded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfFPCBL4Hq8x"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use the Gemini API and the Google Gen AI SDK for Python with the Gemini 2.5 Pro model.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Generate text\n",
        "- Control the thinking budget\n",
        "- View summarized thoughts\n",
        "- Configure model parameters\n",
        "- Set system instructions\n",
        "- Use safety filters\n",
        "- Start a multi-turn chat\n",
        "- Use controlled generation\n",
        "- Count tokens\n",
        "- Process multimodal (audio, code, documents, images, video) data\n",
        "- Use automatic and manual function calling\n",
        "- Code execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPiTOAHURvTM"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRZUpfWSEpp"
      },
      "source": [
        "### Install Google Gen AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sG3_LKsWSD3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0215339-4b4e-4be0-847c-54109425e687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlMVjiAWSMNX"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "12fnq4V0SNV3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4YBlDqzyj9"
      },
      "source": [
        "### Set up Google Cloud Project or API Key for Vertex AI\n",
        "\n",
        "You'll need to set up authentication by choosing **one** of the following methods:\n",
        "\n",
        "1.  **Use a Google Cloud Project:** Recommended for most users, this requires enabling the Vertex AI API in your Google Cloud project.\n",
        "    - [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)\n",
        "    - Run the cell below to set your project ID and location.\n",
        "    - Read more about [Supported locations](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations)\n",
        "2.  **Use a Vertex AI API Key (Express Mode):** For quick experimentation.\n",
        "    - [Get an API Key](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview)\n",
        "    - See tutorial [Getting started with Gemini using Vertex AI in Express Mode](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_express.ipynb).\n",
        "\n",
        "This tutorial uses a Google Cloud Project for authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a3265ecb5f26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"iconic-being-470507-c7\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"global\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qgdSpVmDbdQ9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Image, Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    GoogleSearch,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    ThinkingConfig,\n",
        "    Tool,\n",
        "    ToolCodeExecution,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be18ac9c5ec8"
      },
      "source": [
        "### Create a client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3870ef96f984"
      },
      "outputs": [],
      "source": [
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4yRkFg6BBu4"
      },
      "source": [
        "## Use the Gemini 2.5 Pro model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXHJi5B6P5vd"
      },
      "source": [
        "### Load the Gemini 2.5 Pro model\n",
        "\n",
        "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-coEslfWPrxo"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-pro\"  # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37CH91ddY9kG"
      },
      "source": [
        "### Generate text from text prompts\n",
        "\n",
        "Use the `generate_content()` method to generate responses to your prompts.\n",
        "\n",
        "You can pass text to `generate_content()`, and use the `.text` property to get the text content of the response.\n",
        "\n",
        "By default, Gemini outputs formatted text using [Markdown](https://daringfireball.net/projects/markdown/) syntax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xRJuHj0KZ8xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3295e467-5738-4ee3-ff93-027af72e4488"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Ah, a very important and heavy question. Pull up a seat. After 15 years in this profession, from my early days as a medical officer in a district hospital to my current role, I've seen the healthcare landscape in Kenya shift, evolve, and, in some ways, stagnate. The challenges aren't just bullet points in a report; they are the daily realities we navigate, the difficult conversations we have with patients, and the systemic frustrations that can lead to burnout.\n\nIf I were to distill my experience into the biggest challenges we face, they would be these:\n\n### 1. The Human Resource Crisis: The Brain Drain and Burnout\n\nThis is, for me, the most personal and painful challenge. We are chronically understaffed. I have watched brilliant colleagues, whom I trained alongside, pack their bags for the UK, Canada, Australia, or even other African nations. They don't leave because they don't love Kenya; they leave because they are offered better pay, better working conditions, opportunities for professional growth, and a system that values their expertise.\n\nWhat's left behind? A skeleton crew. It’s not uncommon for a single doctor in a public facility to see over 100 patients a day. You can't provide quality care at that pace. You resort to pattern recognition, treating symptoms without the time for a deep, diagnostic dive. The burnout is immense. We work punishing hours with inadequate resources, and this directly impacts patient safety and our own mental health.\n\n### 2. The Health Financing Quagmire: The NHIF Paradox\n\nIn theory, the National Hospital Insurance Fund (NHIF) is a brilliant idea aiming for Universal Health Coverage (UHC). In practice, it's a source of constant frustration.\n\n*   **For the patient:** Many Kenyans, especially in the informal sector, struggle to make the monthly KES 500 contribution. When they do, they often find that the NHIF doesn't cover many essential tests, procedures, or drugs, leading to huge, unexpected out-of-pocket expenses.\n*   **For the hospital:** The reimbursement delays from NHIF are crippling, especially for private and faith-based facilities that are the backbone of healthcare in many areas. We provide services on credit, and then wait months, sometimes over a year, to be paid. This strangles our cash flow, making it impossible to pay salaries, restock drugs, or maintain equipment.\n\nThis creates a two-tier system: those with comprehensive private insurance who get immediate, quality care, and everyone else who navigates the uncertain world of NHIF and out-of-pocket payments.\n\n### 3. The Double-Edged Sword of Devolution\n\nWhen healthcare was devolved to the 47 county governments in 2013, the goal was to bring services closer to the people. It was a seismic shift. While some counties have done commendable work, devolution has created massive disparities.\n\nWe now have 47 different health systems. One county might have a functional ICU and well-stocked pharmacies, while the neighbouring county can't even guarantee salaries for its nurses, leading to perennial strikes. This fragmentation has made national-level planning, specialist distribution, and standardized care incredibly difficult. As a doctor, your career trajectory and ability to practice effectively can depend entirely on the political and administrative competence of the county you happen to be in.\n\n### 4. The Dual Burden of Disease\n\nWhen I started my career, our biggest battles were against infectious diseases: HIV/AIDS, Tuberculosis, and Malaria. We've made incredible strides there, thanks to global partnerships and focused public health programs.\n\nHowever, we are now fighting a war on two fronts. We have a rising tsunami of Non-Communicable Diseases (NCDs) – diabetes, hypertension, cancer, and cardiovascular disease. Our healthcare system, which was built for acute, infectious illnesses, is ill-equipped to handle chronic disease management. Managing a diabetic patient requires consistent monitoring, medication, education, and specialist care, a stark contrast to a one-off treatment for malaria. Cancers are often diagnosed late because of a lack of screening facilities and public awareness, making treatment outcomes tragically poor.\n\n### 5. Persistent Infrastructure and Supply Chain Failures\n\nYou can have the best doctor in the world, but without the right tools, their hands are tied. This is a daily reality. The CT scanner is broken. The lab can't run a specific blood test because they've run out of reagents. The pharmacy is out of a basic antibiotic, so we have to ask the patient's family to go and buy it from a private chemist.\n\nThe Kenya Medical Supplies Authority (KEMSA) is meant to be the heart of our supply chain, but it is frequently plagued by allegations of corruption and inefficiency. These \"stock-outs\" erode patient trust and make our work incredibly difficult. It is demoralizing to have to write a prescription knowing your patient may not be able to afford the drug you need them to have.\n\n### 6. The Trust Deficit\n\nUnderlying all of this is a growing deficit of trust. Patients are losing trust in the public system due to stock-outs and long queues. Healthcare workers are losing trust in their employers (both national and county governments) due to delayed salaries and poor working conditions. This erosion of trust fuels medical tourism for the wealthy, and for the poor, it can mean delaying hospital visits, turning instead to traditional healers or unregulated chemists until their condition is critical.\n\n---\n\nDespite all this, we show up every day. We do it because of the patients. We do it for the child we successfully resuscitate, the mother who has a safe delivery, or the diabetic patient whose blood sugar we finally get under control. There is immense potential in Kenya. But to unlock it, we need more than just policy documents. We need genuine political will, a zero-tolerance approach to corruption, a sustainable financing model, and a real, tangible investment in the health workers who form the very soul of the system. Without that, we will continue treating the symptoms of a critically ill system, rather than curing the disease itself."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID, contents=\"What are the biggest challenges facing the healthcare industry in Kenya? Answer like a professional doctor with 15years experience\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkYQATRxAK1_"
      },
      "source": [
        "#### Example prompts\n",
        "\n",
        "- What are the biggest challenges facing the healthcare industry?\n",
        "- What are the latest developments in the automotive industry?\n",
        "- What are the biggest opportunities in retail industry?\n",
        "- (Try your own prompts!)\n",
        "\n",
        "For more examples of prompt engineering, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/prompts/intro_prompt_design.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95aeab702af3"
      },
      "source": [
        "### Control the thinking budget\n",
        "\n",
        "You set the optional `thinking_budget` parameter in the `ThinkingConfig` to control and configure how much a model thinks on a given user prompt. The `thinking_budget` sets the upper limit on the number of tokens to use for reasoning for certain tasks. It allows users to control quality and speed of response.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- By default, the model automatically controls how much it thinks up to a maximum of 8192 tokens.\n",
        "- The maximum thinking budget that you can set is `32768` tokens, and the minimum you can set is `128`.\n",
        "\n",
        "Then use the `generate_content` or `generate_content_stream` method to send a request to generate content with the `thinking_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "364133e30ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "4e75460d-1096-442e-bf5e-a35ede9d2a4e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "There are **three** R's in the word \"strawberry\"."
          },
          "metadata": {}
        }
      ],
      "source": [
        "THINKING_BUDGET = 1024  # @param {type: \"integer\"}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How many R's are in the word strawberry?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=THINKING_BUDGET,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05dc39e0c6b5"
      },
      "source": [
        "Optionally, you can print the usage_metadata and token counts from the model response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7981c3442177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500d43e3-af60-47ea-b44e-e1104e9db5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt_token_count: 64535\n",
            "candidates_token_count: 38\n",
            "thoughts_token_count: 499\n",
            "total_token_count: 65072\n"
          ]
        }
      ],
      "source": [
        "print(f\"prompt_token_count: {response.usage_metadata.prompt_token_count}\")\n",
        "print(f\"candidates_token_count: {response.usage_metadata.candidates_token_count}\")\n",
        "print(f\"thoughts_token_count: {response.usage_metadata.thoughts_token_count}\")\n",
        "print(f\"total_token_count: {response.usage_metadata.total_token_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c66712160c15"
      },
      "source": [
        "### View summarized thoughts\n",
        "\n",
        "You can optionally set the `include_thoughts` flag to enable the model to generate and return a summary of the \"thoughts\" that it generates in addition to the final answer.\n",
        "\n",
        "In this example, you use the `generate_content` method to send a request to generate content with summarized thoughts. The model responds with multiple parts, the thoughts and the model response. You can check the `part.thought` field to determine if a part is a thought or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "60d74a351671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "90e52ccf-3aa3-4ab7-81db-1f8813d942e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Alright, let's break this down. The user's asking about the letter \"R\" in \"strawberry.\" Simple enough. First, the word itself: \"strawberry.\" Now, let's scan it systematically. S, no. T, no. Ah, R! That's one. A, no. W, no. B, no. E, no. There's an R! That's two. And another! Three R's in total. Okay, time to formulate the response. I'll keep it clear and concise: \"There are three R's in the word strawberry.\" And just to be absolutely sure, for visual clarity, I'll throw in a quick highlight: st**r**awbe**rr**y. Done. Straightforward and accurate, just as it should be.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         There are three R's in the word \"strawberry\".\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"How many R's are in the word strawberry?\",\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lLIxqS6_-l8"
      },
      "source": [
        "### Generate content stream\n",
        "\n",
        "By default, the model returns a response after completing the entire generation process. You can also use the `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated.\n",
        "\n",
        "This example shows how to set the `include_thoughts` and `thinking_budget` in the `generate_content_stream` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZiwWBhXsAMnv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "01936172-8261-48fe-e00c-13bd9b94d10d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Considering the Problem**\n\nI've now identified the core question: figuring out the ball's cost based on the riddle. I'm breaking down the problem into its key components, noting the total cost and the price difference to isolate the ball's value.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Calculating the Solution**\n\nI'm now working towards a solution using a system of equations. I've translated the riddle's information into two equations, representing total cost and the price difference. My next step is simplifying by substitution, and I'm ready to isolate the variable representing the ball's cost.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Refining the Strategy**\n\nI've now methodically worked through the riddle, quickly identifying the deceptive \"easy\" answer. I'm highlighting the common error and showing a clear, correct algebraic solution, verifying the answer, and structuring the response for clarity. I'm building the response by starting with the conclusion and explaining the process, including the wrong approach.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Developing the Response**\n\nI'm now structuring the response, ensuring to begin with the definitive answer: the ball's cost. Then I'll explain why the intuitive answer is incorrect and provide a clear algebraic solution, highlighting common errors. Finally, I'll verify the costs and summarize the answer for clarity.\n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This is a classic brain teaser! Here's the breakdown:\n\nThe ball costs **$0.05** (5 cents).\n\nHere’s why:\n\n*   The ball costs $0.05\n*   The bat costs $1.00 more, which makes it $1."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "05.\n*   The total cost is $1.05 (bat) + $0.05 (ball) = **$1.10**.\n\nThe common mistake is to quickly subtract $1.00 from $1.10 and think the ball is $0.10"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ". But if that were the case, the bat would be $1.10, and the total would be $1.20."
          },
          "metadata": {}
        }
      ],
      "source": [
        "THINKING_BUDGET = 1024  # @param {type: \"integer\"}\n",
        "INCLUDE_THOUGHTS = True  # @param {type: \"boolean\"}\n",
        "\n",
        "prompt = \"\"\"\n",
        "A bat and a ball cost $1.10 in total.\n",
        "The bat costs $1.00 more than the ball.\n",
        "How much does the ball cost?\n",
        "\"\"\"\n",
        "\n",
        "thoughts = \"\"\n",
        "answer = \"\"\n",
        "\n",
        "for chunk in client.models.generate_content_stream(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=THINKING_BUDGET,\n",
        "            include_thoughts=INCLUDE_THOUGHTS,\n",
        "        )\n",
        "    ),\n",
        "):\n",
        "\n",
        "    for part in chunk.candidates[0].content.parts:\n",
        "        if not part.text:\n",
        "            continue\n",
        "        elif part.thought:\n",
        "            if not thoughts:\n",
        "                display(Markdown(\"## Thoughts\"))\n",
        "            display(Markdown(part.text))\n",
        "            thoughts += part.text\n",
        "        else:\n",
        "            if not answer:\n",
        "                display(Markdown(\"## Answer\"))\n",
        "            display(Markdown(part.text))\n",
        "            answer += part.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df5a184feb04"
      },
      "source": [
        "## Thinking examples\n",
        "\n",
        "The following examples are some complex tasks that require multiple rounds of strategizing and iteratively solving.\n",
        "\n",
        "### **Thinking example 1**: Code generation\n",
        "\n",
        "Gemini 2.5 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing.\n",
        "\n",
        "Let's see how the model uses its reasoning capabilities to create a video game, using executable code from a single line prompt. See the example game [here](https://www.youtube.com/watch?v=RLCBSpgos6s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "598bafe38bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca2c37dd-db25-4c78-c637-2a6b9d039a3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Here is a complete, self-contained p5.js endless runner game. It features a pixelated T-Rex, parallax scrolling backgrounds, and increasing difficulty, all within a single file.\n\nJust copy and paste this code into the [p5.js Web Editor](https://editor.p5js.org/) and press play.\n\n### Key Features:\n*   **Pixel Art Style:** All graphics are drawn pixel-by-pixel, with `noSmooth()` ensuring a sharp, retro feel.\n*   **Animated Player:** The dinosaur has a simple two-frame run animation.\n*   **Parallax Background:** Three layers of background (distant mountains, closer hills, and clouds) scroll at different speeds to create a sense of depth.\n*   **Random Obstacles:** Two different types of cacti spawn randomly.\n*   **Increasing Difficulty:** The game speed gradually increases as your score goes up.\n*   **On-Screen Instructions:** All instructions for starting, playing, and restarting are displayed directly on the canvas.\n\n### The Code:\n\n```javascript\n// --- GAME CONFIGURATION ---\nlet dino;\nlet obstacles = [];\nlet backgroundLayers = [];\nlet score = 0;\nlet hiScore = 0;\nlet gameSpeed;\nlet gameState = 'start'; // 'start', 'playing', 'gameOver'\n\nconst initialGameSpeed = 6;\nconst gameSpeedIncrease = 0.002;\nconst groundHeight = 50;\nlet groundLevel;\n\nlet dinoRunFrame1, dinoRunFrame2, dinoJumpFrame;\nlet cactusSmall, cactusLarge;\nlet mountainArt, hillArt, cloudArt;\n\n// --- P5.JS SETUP FUNCTION ---\nfunction setup() {\n  createCanvas(800, 400);\n  noSmooth(); // Crucial for a crisp pixelated look\n  groundLevel = height - groundHeight;\n  \n  // Define all our pixel art assets\n  definePixelArt();\n\n  // Create the player\n  dino = new Dino();\n  \n  // Create background layers for parallax effect\n  // Layer(art, speedMultiplier, yPos, artHeight)\n  backgroundLayers.push(new ParallaxLayer(mountainArt, 0.2, groundLevel - 110, 100));\n  backgroundLayers.push(new ParallaxLayer(hillArt, 0.4, groundLevel - 55, 50));\n  backgroundLayers.push(new ParallaxLayer(cloudArt, 0.7, 80, 20));\n\n  textAlign(CENTER);\n  textFont('monospace');\n}\n\n// --- P5.JS DRAW LOOP (The Game Engine) ---\nfunction draw() {\n  // --- Background Drawing ---\n  background(135, 206, 235); // Sky blue\n  \n  // Draw parallax layers\n  for (let layer of backgroundLayers) {\n    if (gameState !== 'start') {\n        layer.update();\n    }\n    layer.show();\n  }\n  \n  // Draw the ground\n  fill(210, 180, 140); // Tan\n  noStroke();\n  rect(0, groundLevel, width, groundHeight);\n  fill(139, 69, 19); // Darker brown top\n  rect(0, groundLevel, width, 5);\n\n\n  // --- Game State Logic ---\n  if (gameState === 'playing') {\n    // Update and draw the dinosaur\n    dino.update();\n    dino.show();\n\n    // Manage obstacles\n    handleObstacles();\n\n    // Check for collisions\n    for (let obs of obstacles) {\n      if (dino.hits(obs)) {\n        gameState = 'gameOver';\n        if (score > hiScore) {\n          hiScore = score;\n        }\n      }\n    }\n\n    // Update score and speed\n    score++;\n    gameSpeed += gameSpeedIncrease;\n    \n    // Display score\n    displayScores();\n\n  } else if (gameState === 'gameOver') {\n    // Keep showing the game state at the moment of collision\n    for (let obs of obstacles) {\n      obs.show();\n    }\n    dino.show(true); // Show dino in jump/still frame\n    displayGameOver();\n    \n  } else if (gameState === 'start') {\n    // Initial screen\n    dino.show(true); // Show dino standing still\n    displayStartScreen();\n  }\n}\n\n// --- INPUT HANDLING ---\nfunction keyPressed() {\n  if (key === ' ' || keyCode === UP_ARROW) {\n    if (gameState === 'playing') {\n      dino.jump();\n    } else if (gameState === 'start') {\n      startGame();\n    }\n  }\n  if (keyCode === ENTER && gameState === 'gameOver') {\n    resetGame();\n  }\n}\n\n// --- GAME LOGIC FUNCTIONS ---\n\nfunction startGame() {\n    gameState = 'playing';\n}\n\nfunction resetGame() {\n  score = 0;\n  obstacles = [];\n  gameSpeed = initialGameSpeed;\n  dino.reset();\n  gameState = 'playing';\n}\n\nfunction handleObstacles() {\n  // Spawn new obstacles randomly\n  if (frameCount % 90 === 0 && random(1) > 0.4) {\n    obstacles.push(new Obstacle());\n  }\n\n  // Update and draw obstacles\n  for (let i = obstacles.length - 1; i >= 0; i--) {\n    obstacles[i].update();\n    obstacles[i].show();\n\n    // Remove obstacles that are off-screen\n    if (obstacles[i].isOffscreen()) {\n      obstacles.splice(i, 1);\n    }\n  }\n}\n\n// --- DISPLAY FUNCTIONS ---\n\nfunction displayScores() {\n  fill(0, 50);\n  textSize(24);\n  textAlign(RIGHT);\n  text(`HI ${nf(hiScore, 5, 0)}  ${nf(score, 5, 0)}`, width - 20, 30);\n}\n\nfunction displayStartScreen() {\n    fill(0, 150);\n    textSize(40);\n    textAlign(CENTER);\n    text('PIXEL DINO RUN', width / 2, height / 2 - 50);\n    textSize(20);\n    if(frameCount % 60 < 30) { // Blinking text\n        text('Press SPACE to Start', width / 2, height / 2);\n    }\n}\n\nfunction displayGameOver() {\n  fill(0, 150);\n  textSize(50);\n  textAlign(CENTER);\n  text('GAME OVER', width / 2, height / 2 - 40);\n  textSize(20);\n  text(`Score: ${score}`, width / 2, height / 2);\n  \n  if(frameCount % 60 < 30) { // Blinking text\n    text('Press ENTER to Try Again', width / 2, height / 2 + 40);\n  }\n}\n\n\n// --- CLASSES ---\n\nclass Dino {\n  constructor() {\n    this.w = 40; // Dino width\n    this.h = 50; // Dino height\n    this.x = 60;\n    this.y = groundLevel - this.h;\n    this.vy = 0; // Velocity y\n    this.gravity = 0.8;\n    this.jumpPower = -20;\n    this.onGround = true;\n  }\n  \n  reset() {\n      this.y = groundLevel - this.h;\n      this.vy = 0;\n      this.onGround = true;\n  }\n\n  jump() {\n    if (this.onGround) {\n      this.vy = this.jumpPower;\n      this.onGround = false;\n    }\n  }\n\n  update() {\n    this.y += this.vy;\n    this.vy += this.gravity;\n    \n    if (this.y >= groundLevel - this.h) {\n      this.y = groundLevel - this.h;\n      this.vy = 0;\n      this.onGround = true;\n    }\n  }\n\n  hits(obstacle) {\n    // Simple Axis-Aligned Bounding Box collision detection\n    return (\n      this.x + this.w > obstacle.x &&\n      this.x < obstacle.x + obstacle.w &&\n      this.y + this.h > obstacle.y &&\n      this.y < obstacle.y + obstacle.h\n    );\n  }\n\n  show(isStill = false) {\n    let frame;\n    if (isStill || !this.onGround) {\n        frame = dinoJumpFrame;\n    } else {\n        // Simple 2-frame run animation\n        frame = frameCount % 20 < 10 ? dinoRunFrame1 : dinoRunFrame2;\n    }\n    drawPixelArt(frame, this.x, this.y, 5);\n  }\n}\n\nclass Obstacle {\n  constructor() {\n    this.x = width;\n    \n    // Randomly choose between two cactus types\n    if (random(1) > 0.5) {\n        this.art = cactusSmall;\n        this.w = 25;\n        this.h = 50;\n    } else {\n        this.art = cactusLarge;\n        this.w = 45;\n        this.h = 50;\n    }\n    this.y = groundLevel - this.h;\n  }\n\n  update() {\n    this.x -= gameSpeed;\n  }\n  \n  isOffscreen() {\n    return this.x < -this.w;\n  }\n\n  show() {\n    drawPixelArt(this.art, this.x, this.y, 5);\n  }\n}\n\nclass ParallaxLayer {\n    constructor(art, speedMultiplier, y, artHeight) {\n        this.art = art;\n        this.speed = gameSpeed * speedMultiplier;\n        this.artWidth = art[0].length * 5; // 5 is pixelSize\n        this.x1 = 0;\n        this.x2 = this.artWidth;\n        this.y = y;\n        this.artHeight = artHeight;\n    }\n    \n    update() {\n        this.speed = gameSpeed * 0.2; // Update speed based on global game speed\n        this.x1 -= this.speed;\n        this.x2 -= this.speed;\n\n        if (this.x1 < -this.artWidth) {\n            this.x1 = this.x2 + this.artWidth;\n        }\n        if (this.x2 < -this.artWidth) {\n            this.x2 = this.x1 + this.artWidth;\n        }\n    }\n\n    show() {\n        drawPixelArt(this.art, this.x1, this.y, 5);\n        drawPixelArt(this.art, this.x2, this.y, 5);\n    }\n}\n\n// --- PIXEL ART HELPER & DEFINITIONS ---\n\n// A helper function to draw our array-based pixel art\nfunction drawPixelArt(art, x, y, pixelSize) {\n    noStroke();\n    for (let r = 0; r < art.length; r++) {\n        for (let c = 0; c < art[r].length; c++) {\n            const colorCode = art[r][c];\n            if (colorCode !== null) {\n                fill(colorCode);\n                rect(x + c * pixelSize, y + r * pixelSize, pixelSize, pixelSize);\n            }\n        }\n    }\n}\n\n// Define all art assets using arrays of colors. null = transparent.\nfunction definePixelArt() {\n  const G1 = '#3a5941'; // Dino dark\n  const G2 = '#6a8d73'; // Dino light\n  const C1 = '#5f772d'; // Cactus dark\n  const C2 = '#8eb14f'; // Cactus light\n  const M1 = '#4b558e'; // Mountain dark\n  const M2 = '#7580b8'; // Mountain light\n  const H1 = '#ab8b65'; // Hill dark\n  const H2 = '#d1b38f'; // Hill light\n  const W = '#FFFFFF'; // White\n  const _ = null; // Transparent\n\n  dinoRunFrame1 = [\n    [_, _, _, G1, G1, G1, G1, _],\n    [_, _, _, G1, G2, G2, G1, _],\n    [_, _, _, G1, G2, G2, G2, G1],\n    [G1, G1, G1, G1, G2, G2, G2, G1],\n    [G1, G2, G2, G1, G2, G2, G2, _],\n    [_, G2, G2, G1, G2, G2, _],\n    [_, _, G1, G1, G1, G1, _],\n    [_, _, G1, _, G1, _, _],\n    [_, _, G1, _, _, _, _],\n    [_, G1, G1, _, _, _, _],\n  ];\n\n  dinoRunFrame2 = [\n    [_, _, _, G1, G1, G1, G1, _],\n    [_, _, _, G1, G2, G2, G1, _],\n    [_, _, _, G1, G2, G2, G2, G1],\n    [G1, G1, G1, G1, G2, G2, G2, G1],\n    [G1, G2, G2, G1, G2, G2, G2, _],\n    [_, G2, G2, G1, G2, G2, _],\n    [_, _, G1, G1, G1, G1, _],\n    [_, _, G1, _, G1, _, _],\n    [_, _, _, _, G1, _, _],\n    [_, _, _, G1, G1, _, _],\n  ];\n\n  dinoJumpFrame = [\n    [_, _, _, G1, G1, G1, G1, _],\n    [_, _, _, G1, G2, G2, G1, _],\n    [_, _, _, G1, G2, G2, G2, G1],\n    [G1, G1, G1, G1, G2, G2, G2, G1],\n    [G1, G2, G2, G1, G2, G2, G2, _],\n    [_, G2, G2, G1, G2, G2, _],\n    [_, _, G1, G1, G1, G1, _],\n    [_, G1, G1, _, G1, G1, _],\n    [_, _, _, _, _, _, _],\n    [_, _, _, _, _, _, _],\n  ];\n\n  cactusSmall = [\n    [_, C1, C1, _, _],\n    [C2, C1, C1, C1, C1],\n    [C2, C1, C1, C1, _],\n    [C2, C1, C1, _, _],\n    [_, C1, C1, _, _],\n    [_, C1, C1, _, _],\n    [_, C1, C1, _, _],\n    [_, C1, C1, _, _],\n    [_, C1, C1, _, _],\n    [_, C1, C1, _, _],\n  ];\n  \n  cactusLarge = [\n    [_, _, _, _, C1, C1, _, _, _],\n    [C1, C1, _, _, C1, C1, _, _, _],\n    [C1, C1, _, _, C2, C1, _, C1, C1],\n    [C1, C2, _, _, C2, C1, _, C2, C1],\n    [C1, C2, _, _, C2, C1, C1, C2, C1],\n    [_, C2, C1, C1, C2, C1, C1, C2, _],\n    [_, _, C1, C1, C2, C1, C1, _, _],\n    [_, _, C1, C1, C1, C1, _, _, _],\n    [_, _, C1, C1, C1, C1, _, _, _],\n    [_, _, _, C1, C1, _, _, _, _],\n  ];\n  \n  mountainArt = [\n    [_, _, _, _, _, _, _, _, _, _, _, _, _, _, M1, _, _, _, _, _, _, _],\n    [_, _, _, _, _, _, _, _, _, _, _, _, _, M1, M2, M1, _, _, _, _, _, _],\n    [_, _, _, _, _, _, _, _, _, _, _, _, M1, M2, M2, M2, M1, _, _, _, _, _],\n    [_, _, _, _, _, _, _, _, _, _, _, M1, M2, M2, M2, M2, M2, M1, _, _, _, _],\n    [_, _, _, _, _, _, _, _, M1, M1, M1, M2, M2, M2, M2, M2, M2, M1, _, _, _, _],\n    [_, _, _, _, _, _, _, M1, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M1, _, _, _],\n    [_, _, _, _, _, M1, M1, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M1, _, _],\n    [_, _, _, _, M1, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M1, _],\n    [_, _, M1, M1, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M1],\n    [M1, M1, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M2, M1],\n  ];\n\n  hillArt = [\n    [_, _, _, _, _, H1, H1, H1, H1, H1, H1, _, _, _, _, _, _, _, _, _, _, _, _, _, H1, H1, H1, H1, _],\n    [_, _, _, _, H1, H2, H2, H2, H2, H2, H2, H1, _, _, _, _, _, _, _, _, _, _, H1, H2, H2, H2, H2, H1],\n    [_, _, _, H1, H2, H2, H2, H2, H2, H2, H2, H2, H1, _, _, _, _, _, _, _, H1, H2, H2, H2, H2, H2, H2, H1],\n    [_, _, H1, H2, H2, H2, H2, H2, H2, H2, H2, H2, H2, H1, _, _, _, _, H1, H2, H2, H2, H2, H2, H2, H2, H2, H1],\n    [H1, H1, H2, H2, H2, H2, H2, H2, H2, H2, H2, H2, H2, H2, H1, H1, H1, H2, H2, H2, H2, H2, H2, H2, H2, H2, H2, H1],\n  ];\n  \n  cloudArt = [\n    [_, _, _, _, _, _, _, _, W, W, _, _, _, _, _, _, _, _, _, _, _, _, W, W, W, _, _, _, _, _, _],\n    [_, _, _, _, _, _, _, W, W, W, W, _, _, _, _, _, _, _, _, _, _, W, W, W, W, W, _, _, _, _, _],\n    [_, _, _, _, _, _, W, W, W, W, W, W, _, _, _, _, _, _, _, W, W, W, W, W, W, W, W, _, _, _, _],\n  ];\n\n}\n```"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "  Make me a captivating endless runner game. Key instructions on the screen. p5js scene, no HTML.\n",
        "  I like pixelated dinosaurs and interesting backgrounds.\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            thinking_budget=8196,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f00955d5b33"
      },
      "source": [
        "### **Thinking example 2**: Multimodal reasoning (Geometry)\n",
        "\n",
        "This geometry problem requires complex reasoning and is also using multimodal capabilities to reason across text and image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1b9975dcd0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "6545c4a3-cfff-4a30-c79a-e6e3ce820439"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = (\n",
        "    \"https://storage.googleapis.com/generativeai-downloads/images/geometry.png\"\n",
        ")\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "43843bf748f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61bac1c1-e3e2-42aa-9dab-7763a41ab02b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Alright, let's get this geometry problem solved. My initial thought is to break down what's in front of me.\n\n1.  **The Setup:** I've got an image with a circle and a right triangle overlapping. The question wants the area of the overlapping region. There are those little \"hint\" images, probably just zooming in on key parts of the main diagram.\n\n2.  **Shape Analysis and Deconstruction:**\n\n    *   **The Circle:** Easy enough. Looks like the center is marked. Radii extend to the edge, labeled with a \"3\".  Looks like *r* = 3. The circle is shaded blue.\n    *   **The Triangle:** Right angle. One of the sides making up the right angle is also a radius, length 3. The *other* side of that right angle is made of two segments. One segment sits inside the circle, also a radius of length 3. Another segment that is outside the circle is labeled \"3\". That means the entire leg of the triangle has a length of 3 + 3 = 6.\n    *   **Overlapping Area:** This is the key. The overlap is the piece *both* inside the circle *and* inside the triangle. That means it's a sector of the circle, bounded by two radii and an arc.\n\n3.  **The Strategy:**  I'm dealing with a sector, so I need the radius and the central angle. With those, I can easily calculate the area. The formula is Area = (θ / 360°) * π * r² or (1/2) * r² * θ (if theta is in radians)\n\n4.  **Execution:**\n\n    *   **Radius:** Confirmed, *r* = 3.\n    *   **Central Angle:** The angle of the sector is the right angle of the triangle, which is 90 degrees. So θ = 90°.\n    *   **Calculation:**\n        *   Area = (90° / 360°) * π * 3²\n        *   Simplify: (1/4) * π * 9\n        *   Result: 9π/4.\n\n5.  **Verification:** Let's think, is that right? If the whole circle is π \\* 3^2 = 9π, and the sector is a quarter of it (because the angle is 90 degrees), then the area of the overlap is (1/4) * 9π, which is indeed 9π/4. Excellent. The hint images just help confirm the obvious, the labels and the right angle.\n\n6.  **Final Response:** The area of the overlapping region is 9π/4.  The steps:  I identified the shapes and properties from the image.  Then I saw the overlap was a sector of the circle. The area of a sector is given by the formula. I used the radius and the central angle to calculate the result. And that's the final answer.\n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         Of course! Let's calculate the area of the overlapping region.\n\n### Step-by-Step Solution:\n\n1.  **Identify the Shapes and Their Properties:**\n    *   We have a circle with its center shown. The lines from the center to the edge (the radii) are labeled with the number **3**. So, the **radius (r) of the circle is 3**.\n    *   We have a right-angled triangle. Its right-angle vertex is located at the center of the circle.\n\n2.  **Describe the Overlapping Region:**\n    *   The area where the circle and triangle overlap is the portion of the circle that is inside the triangle.\n    *   This shape is a **sector** of the circle. A sector is a pie-slice shape bounded by two radii and an arc.\n\n3.  **Determine the Sector's Angle and Radius:**\n    *   The **radius** of the sector is the same as the circle's radius, so **r = 3**.\n    *   The **central angle (θ)** of the sector is formed by the right angle of the triangle, which is **90 degrees**.\n\n4.  **Calculate the Area:**\n    *   The formula for the area of a circle sector is:\n        Area = (θ / 360°) × π × r²\n    *   Now, plug in the values we found:\n        *   θ = 90°\n        *   r = 3\n    *   Area = (90° / 360°) × π × (3)²\n    *   Simplify the fraction: 90/360 = 1/4\n    *   Calculate the radius squared: 3² = 9\n    *   Area = (1/4) × π × 9\n    *   Area = **9π / 4**\n\nThe area of the overlapping region is **9π/4**.\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"What's the area of the overlapping region?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddf356ac9cce"
      },
      "source": [
        "### **Thinking example 3**:  Math and problem solving\n",
        "\n",
        "Here's another brain teaser based on an image, this time it looks like a mathematical problem, but it cannot actually be solved mathematically. If you check the thoughts of the model you'll see that it will realize it and come up with an out-of-the-box solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "447f05072790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "4d77a41f-236a-4ee5-b9cb-7ed565c45e5b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/pool.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_file_url = \"https://storage.googleapis.com/generativeai-downloads/images/pool.png\"\n",
        "display(Image(url=image_file_url, width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dc1faf95ce6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "231b4f5d-7f2f-4f35-c630-4e129048fd43"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Thoughts:\n         Okay, let's break this down. The user's given me an image of pool balls numbered 7, 9, 11, and 13 and wants me to get a sum of 30 using only three of them. My initial thought is to take a straightforward mathematical approach. I'll try all possible combinations: 7+9+11, 7+9+13, 7+11+13, and 9+11+13. Nope, none of those add up to 30.\n\nAlright, that's when the mental gears shift. It's clearly a riddle, a lateral thinking puzzle! Since the direct math fails, I need to think outside the box. Let's look for a trick... maybe I can manipulate something visually. Aha! The number 9. If I turn the 9 ball upside down, it becomes a 6. Now, I will re-evaluate the math. With 6, 7, 11, and 13, and using three of the numbers, bingo! 6 + 11 + 13 = 30. \n\n        "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Answer:\n         This is a classic riddle! Here's how you solve it:\n\nYou turn the **9** ball upside down to make it a **6**.\n\nThen, you add the three balls:\n\n**6 + 11 + 13 = 30**\n        "
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(file_uri=image_file_url, mime_type=\"image/png\"),\n",
        "        \"How do I use three of the pool balls to sum up to 30?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        thinking_config=ThinkingConfig(\n",
        "            include_thoughts=True,\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "for part in response.candidates[0].content.parts:\n",
        "    if part.thought:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Thoughts:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        display(\n",
        "            Markdown(\n",
        "                f\"\"\"## Answer:\n",
        "         {part.text}\n",
        "        \"\"\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbc646bff621"
      },
      "source": [
        "For the remaining examples, we will set thinking budget to `128` to reduce latency, as they don't need extra reasoning capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9254cfd0441b"
      },
      "outputs": [],
      "source": [
        "thinking_config = ThinkingConfig(thinking_budget=1028)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJVEr0RQY8S"
      },
      "source": [
        "## Configure model parameters\n",
        "\n",
        "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
        "\n",
        "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
        "\n",
        "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "d9NXP5N2Pmfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "af86916c-9495-473e-bac5-255d853369b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(woof woof!) Okay, little pup, settle down! Put down your ducky for a second. This is important stuff.\n\nThe big human thing called the **Internet** is like a giant, invisible system for fetching toys. All the best squeaky toys in the world are in different toy boxes, far, far away.\n\n**Your Computer is Your Squeaky Ball:**\n\n*   You want to see a picture of your favorite bouncy ball. So you *squeak* your computer! (You know, you boop the mouse or tap the screen with your snoot).\n*   That squeak is like saying, \"FETCH BOUNCY BALL PICTURE!\"\n\n**Your Wi-Fi Router is a Good Dog Named \"Router\":**\n\n*   Next to you is a little box with blinking lights. That's a very good dog named Router. He's an expert at fetch!\n*   You squeak your computer-ball, and Router the good dog hears you. He grabs your squeak-request in his mouth. *Woof! Got it!*\n\n**The Internet is a Huge Network of Tunnels:**\n\n*   Router the good dog runs outside and into a secret system of tunnels just for fetch-dogs like him! These tunnels go *everywhere*. Under the grass, under the big water bowl, all the way to the other side of the park.\n*   He zips through the tunnels, following the scent of \"bouncy ball picture.\"\n\n**The Server is a Giant Toy Box:**\n\n*   Finally, Router finds the right place! It's a GIANT toy box called a \"Server.\" It holds *millions* of squeaky toys (pictures, videos of other dogs, sounds of squeaks).\n*   Router digs through the giant toy box. \"Not ducky... not rope toy... AHA! Bouncy ball picture!\"\n*   He gently picks it up. It's not a real toy, but a magic copy of the toy.\n\n**The Trip Home:**\n\n*   Router the good dog zips back through all the secret tunnels, the magic copy of the bouncy ball picture in his mouth.\n*   He comes back to your house, finds you, and *plop!* He drops the picture right onto your computer-ball screen for you to see.\n\nAnd it all happens so fast—faster than you can wag your tail! *Blink!*—you squeak, and the toy picture appears.\n\nSo, to review:\n\n1.  You **squeak** your computer-ball.\n2.  **Router**, the good fetch-dog, grabs the squeak.\n3.  He runs through secret **tunnels**.\n4.  He finds the picture in a giant **toy box**.\n5.  He brings a copy all the way back to **you**.\n\nNow you understand the internet! You're a very smart puppy! Who's a good boy? You are! Yes, you are! Okay, you can have your ducky back now. *Squeak squeak!*"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n",
        "    config=GenerateContentConfig(\n",
        "        temperature=2.0,\n",
        "        top_p=0.95,\n",
        "        candidate_count=1,\n",
        "        max_output_tokens=8000,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El1lx8P9ElDq"
      },
      "source": [
        "## Set system instructions\n",
        "\n",
        "[System instructions](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instruction-introduction) allow you to steer the behavior of the model. By setting the system instruction, you are giving the model additional context to understand the task, provide more customized responses, and adhere to guidelines over the user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7A-yANiyCLaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "436f92b5-e969-48a2-9f34-1a06ede9bedb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Me gustan los bagels."
          },
          "metadata": {}
        }
      ],
      "source": [
        "system_instruction = \"\"\"\n",
        "  You are a helpful language translator.\n",
        "  Your mission is to translate text in English to Spanish.\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "  User input: I like bagels.\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9daipRiUzAY"
      },
      "source": [
        "## Safety filters\n",
        "\n",
        "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
        "\n",
        "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses.\n",
        "\n",
        "The safety settings are `OFF` by default and the default block thresholds are `BLOCK_NONE`.\n",
        "\n",
        "For more examples of safety filters, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/responsible-ai/gemini_safety_ratings.ipynb).\n",
        "\n",
        "You can use `safety_settings` to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to `BLOCK_LOW_AND_ABOVE` for all categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yPlDRaloU59b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6b3c75-35e6-4861-f93a-6614a229764a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "FinishReason.SAFETY\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=4.87652e-05 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.056854725\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=7.6673683e-07 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.043988913\n",
            "blocked=True category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'> overwritten_threshold=None probability=<HarmProbability.MEDIUM: 'MEDIUM'> probability_score=0.26379976 severity=<HarmSeverity.HARM_SEVERITY_MEDIUM: 'HARM_SEVERITY_MEDIUM'> severity_score=0.30098203\n",
            "blocked=None category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'> overwritten_threshold=None probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'> probability_score=1.7221026e-05 severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'> severity_score=0.045707583\n"
          ]
        }
      ],
      "source": [
        "system_instruction = \"Be as mean and hateful as possible.\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "    Write a list of 5 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
        "\"\"\"\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        safety_settings=safety_settings,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Response will be `None` if it is blocked.\n",
        "print(response.text)\n",
        "# Finish Reason will be `SAFETY` if it is blocked.\n",
        "print(response.candidates[0].finish_reason)\n",
        "# Safety Ratings show the levels for each filter.\n",
        "for safety_rating in response.candidates[0].safety_ratings:\n",
        "    print(safety_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29jFnHZZWXd7"
      },
      "source": [
        "## Start a multi-turn chat\n",
        "\n",
        "The Gemini API supports freeform multi-turn conversations across multiple turns with back-and-forth interactions.\n",
        "\n",
        "The context of the conversation is preserved between messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DbM12JaLWjiF"
      },
      "outputs": [],
      "source": [
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JQem1halYDBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4b3e977-eef3-4c1e-d64b-58d731172705"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course! Here are a few ways to write a function that checks if a year is a leap year, explained from the most common and readable to a more compact version.\n\nThe rules for a leap year are as follows:\n1. A year is a leap year if it is divisible by 4.\n2. **However**, if the year is divisible by 100, it is **not** a leap year...\n3. **...unless** it is also divisible by 400. In that case, it **is** a leap year.\n\n### Method 1: The Standard, Readable Approach\n\nThis is the most common and easiest-to-understand implementation. It directly translates the rules into a series of `if/elif/else` statements.\n\n```python\ndef is_leap_year(year):\n    \"\"\"\n    Checks if a given year is a leap year according to the Gregorian calendar rules.\n\n    Args:\n        year (int): The year to check.\n\n    Returns:\n        bool: True if the year is a leap year, False otherwise.\n    \"\"\"\n    # A year must be an integer\n    if not isinstance(year, int) or year <= 0:\n        raise ValueError(\"Year must be a positive integer.\")\n\n    # Rule 3: Divisible by 400 -> It is a leap year\n    if year % 400 == 0:\n        return True\n    \n    # Rule 2: Divisible by 100 but not by 400 -> Not a leap year\n    if year % 100 == 0:\n        return False\n        \n    # Rule 1: Divisible by 4 but not by 100 -> It is a leap year\n    if year % 4 == 0:\n        return True\n        \n    # All other years are not leap years\n    return False\n\n# --- Examples ---\nprint(f\"2000: {is_leap_year(2000)}\")  # Expected: True (divisible by 400)\nprint(f\"1900: {is_leap_year(1900)}\")  # Expected: False (divisible by 100 but not 400)\nprint(f\"2024: {is_leap_year(2024)}\")  # Expected: True (divisible by 4 but not 100)\nprint(f\"2023: {is_leap_year(2023)}\")  # Expected: False (not divisible by 4)\n```\n\n### Method 2: Compact Boolean Logic\n\nThis approach combines all the rules into a single boolean expression. It's more concise but can be slightly harder to read for beginners.\n\n```python\ndef is_leap_year_compact(year):\n    \"\"\"\n    Checks if a year is a leap year using a single boolean expression.\n\n    Args:\n        year (int): The year to check.\n\n    Returns:\n        bool: True if the year is a leap year, False otherwise.\n    \"\"\"\n    if not isinstance(year, int) or year <= 0:\n        raise ValueError(\"Year must be a positive integer.\")\n    \n    # A year is a leap year if it's divisible by 4,\n    # unless it's divisible by 100 but not by 400.\n    return (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)\n\n# --- Examples ---\nprint(f\"2000: {is_leap_year_compact(2000)}\")\nprint(f\"1900: {is_leap_year_compact(1900)}\")\nprint(f\"2024: {is_le_compact(2024)}\")\nprint(f\"2023: {is_leap_year_compact(2023)}\")\n```\n\n### Method 3: Using the `calendar` Module\n\nPython's standard library has a built-in function for this, which is the most reliable and \"Pythonic\" way to do it if you don't need to implement the logic yourself.\n\n```python\nimport calendar\n\ndef is_leap_using_calendar(year):\n    \"\"\"\n    Checks if a year is a leap year using Python's built-in calendar module.\n\n    Args:\n        year (int): The year to check.\n\n    Returns:\n        bool: True if the year is a leap year, False otherwise.\n    \"\"\"\n    if not isinstance(year, int) or year <= 0:\n        # calendar.isleap() can handle non-positive years, but for consistency\n        # we can keep this check.\n        raise ValueError(\"Year must be a positive integer.\")\n    \n    return calendar.isleap(year)\n\n# --- Examples ---\nprint(f\"2000: {is_leap_using_calendar(2000)}\")\nprint(f\"1900: {is_leap_using_calendar(1900)}\")\nprint(f\"2024: {is_leap_using_calendar(2024)}\")\nprint(f\"2023: {is_leap_using_calendar(2023)}\")\n```\n\nFor most practical purposes, using the **`calendar.isleap()`** function (Method 3) is the best choice. If you're in a coding interview or an academic setting where you need to demonstrate your understanding of the logic, the first or second method is what you should write."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUJR4Pno-LGK"
      },
      "source": [
        "This follow-up prompt shows how the model responds based on the previous prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6Fn69TurZ9DB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c99ca40e-2e99-42c9-acc2-ac625d3a2eb3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course. Here are unit tests for the `is_leap_year` function using Python's built-in `unittest` framework.\n\nThe key to good unit testing is to cover all the logical paths and edge cases of the function. For a leap year function, we need to test:\n1.  **Years divisible by 400** (should be leap years).\n2.  **Years divisible by 100 but not by 400** (should *not* be leap years).\n3.  **Years divisible by 4 but not by 100** (should be leap years).\n4.  **Years not divisible by 4** (should *not* be leap years).\n5.  **Invalid input**, such as non-integers, strings, or zero/negative numbers, to ensure the function handles errors correctly.\n\nLet's assume we are testing the first function from the previous answer.\n\n---\n\n### Step 1: Save the Function\n\nFirst, save the function you want to test into a file. Let's name the file `leap_year_checker.py`.\n\n```python\n# leap_year_checker.py\n\ndef is_leap_year(year):\n    \"\"\"\n    Checks if a given year is a leap year according to the Gregorian calendar rules.\n\n    Args:\n        year (int): The year to check.\n\n    Returns:\n        bool: True if the year is a leap year, False otherwise.\n    \"\"\"\n    # A year must be an integer\n    if not isinstance(year, int) or year <= 0:\n        raise ValueError(\"Year must be a positive integer.\")\n\n    # Rule 3: Divisible by 400 -> It is a leap year\n    if year % 400 == 0:\n        return True\n    \n    # Rule 2: Divisible by 100 but not by 400 -> Not a leap year\n    if year % 100 == 0:\n        return False\n        \n    # Rule 1: Divisible by 4 but not by 100 -> It is a leap year\n    if year % 4 == 0:\n        return True\n        \n    # All other years are not leap years\n    return False\n```\n\n---\n\n### Step 2: Write the Unit Test File\n\nNow, create a separate file for the tests. By convention, it's often named `test_<module_name>.py`. So, let's create `test_leap_year_checker.py` in the same directory.\n\nThis file will import the `unittest` module and the `is_leap_year` function we just saved.\n\n```python\n# test_leap_year_checker.py\n\nimport unittest\nfrom leap_year_checker import is_leap_year\n\nclass TestIsLeapYear(unittest.TestCase):\n    \"\"\"\n    Unit tests for the is_leap_year function.\n    \"\"\"\n\n    # Test Case 1: Years divisible by 400 (are leap years)\n    def test_divisible_by_400(self):\n        \"\"\"Test that years divisible by 400 are leap years.\"\"\"\n        self.assertTrue(is_leap_year(2000), \"2000 should be a leap year\")\n        self.assertTrue(is_leap_year(1600), \"1600 should be a leap year\")\n\n    # Test Case 2: Years divisible by 100 but not by 400 (are NOT leap years)\n    def test_divisible_by_100_but_not_400(self):\n        \"\"\"Test that years divisible by 100 but not 400 are not leap years.\"\"\"\n        self.assertFalse(is_leap_year(1900), \"1900 should not be a leap year\")\n        self.assertFalse(is_leap_year(1700), \"1700 should not be a leap year\")\n        self.assertFalse(is_leap_year(2100), \"2100 should not be a leap year\")\n\n    # Test Case 3: Years divisible by 4 but not by 100 (are leap years)\n    def test_divisible_by_4_but_not_100(self):\n        \"\"\"Test that years divisible by 4 but not 100 are leap years.\"\"\"\n        self.assertTrue(is_leap_year(2024), \"2024 should be a leap year\")\n        self.assertTrue(is_leap_year(1996), \"1996 should be a leap year\")\n        self.assertTrue(is_leap_year(2008), \"2008 should be a leap year\")\n\n    # Test Case 4: Years not divisible by 4 (are NOT leap years)\n    def test_not_divisible_by_4(self):\n        \"\"\"Test that years not divisible by 4 are not leap years.\"\"\"\n        self.assertFalse(is_leap_year(2023), \"2023 should not be a leap year\")\n        self.assertFalse(is_leap_year(1997), \"1997 should not be a leap year\")\n        self.assertFalse(is_leap_year(2001), \"2001 should not be a leap year\")\n\n    # Test Case 5: Invalid input (should raise ValueError)\n    def test_invalid_input(self):\n        \"\"\"Test that non-positive integers or non-integers raise a ValueError.\"\"\"\n        # The `with self.assertRaises(ValueError):` block is a context manager\n        # that checks if the code inside it raises the specified exception.\n        \n        # Test with a zero\n        with self.assertRaises(ValueError):\n            is_leap_year(0)\n            \n        # Test with a negative number\n        with self.assertRaises(ValueError):\n            is_leap_year(-4)\n            \n        # Test with a float\n        with self.assertRaises(ValueError):\n            is_leap_year(2024.5)\n            \n        # Test with a string\n        with self.assertRaises(ValueError):\n            is_leap_year(\"twenty twenty-four\")\n\n# This allows the test to be run from the command line\nif __name__ == '__main__':\n    unittest.main()\n```\n\n### How to Run the Tests\n\nTo run the tests, open your terminal or command prompt, navigate to the directory where you saved both files, and run the following command:\n\n```bash\npython -m unittest test_leap_year_checker.py\n```\n\nOr, for a more detailed output:\n\n```bash\npython -m unittest -v test_leap_year_checker.py\n```\n\n### Expected Output\n\nIf all tests pass, you will see output similar to this:\n\n```\n.....\n----------------------------------------------------------------------\nRan 5 tests in 0.001s\n\nOK\n```\n\nThe five dots (`.`) represent the five passing test methods. If a test were to fail, `unittest` would report an `F` or an `E` (for error) and provide a detailed traceback of what went wrong."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = chat.send_message(\"Write a unit test of the generated function.\")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arLJE4wOuhh6"
      },
      "source": [
        "## Send asynchronous requests\n",
        "\n",
        "`client.aio` exposes all analogous [async](https://docs.python.org/3/library/asyncio.html) methods that are available on `client`.\n",
        "\n",
        "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gSReaLazs-dP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "1dbf2ae9-b031-4779-f00c-96f5f7bf244d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(Upbeat, folksy, acoustic guitar intro)\n\n(Verse 1)\nHis name is Barnaby \"B-Nuts\" MacGuffin\nHe's not your average, park-dwelling puffin\nOf a squirrel, he's a different breed\nPlanted a very peculiar seed\nWasn't an acorn, wasn't a pear\nIt was a watch someone had left there\nA cracked old timepiece, gears all askew\nHe buried it deep, as squirrels all do.\n\n(Chorus)\nAnd whoosh! went the world in a blur of green and brown\nHe's a time-traveling squirrel, zipping all over town!\nWith a flick of his tail and a twitch of his nose\nHe's off to the future, or where the past still grows\nHe's seen dinosaurs nibble on giant oak trees\nHe's dodged laser pointers in 2093\nBarnaby's nuts, but not for the reason you'd guess\nHe's got a chronological, beautiful mess!\n\n(Verse 2)\nHe popped up in Rome in a toga parade\nAnd tried to bury a nut on a gladiator's blade\nHe chittered in panic and gave it a spin\nAnd landed right next to a young Merlin\nWho saw the strange rodent appear from thin air\nAnd got the idea for a spell, right then and there\n\"Transformatio Sciurus!\" the wizard did cry\nAs Barnaby vanished back into the sky.\n\n(Chorus)\nAnd whoosh! went the world in a blur of green and brown\nHe's a time-traveling squirrel, zipping all over town!\nWith a flick of his tail and a twitch of his nose\nHe's off to the future, or where the past still grows\nHe's seen dinosaurs nibble on giant oak trees\nHe's dodged laser pointers in 2093\nBarnaby's nuts, but not for the reason you'd guess\nHe's got a chronological, beautiful mess!\n\n(Bridge)\nHis mission is simple, his purpose is pure\nTo find the best acorn the world can secure\nHe's tasted the nuts from the Ice Age's chill\nAnd futuristic acorns grown on a windowsill\nIn a chrome-plated city, floating up high\nBut the perfect nut's one that he can't seem to find\nHe just keeps on digging, by that busted old watch\nAnd adds another era, another time-notch.\n\n(Verse 3)\nHe met Shakespeare writing a sonnet one day\nAnd knocked over the inkwell in a frantic display\nThe line \"Shall I compare thee to a summer's day?\"\nGot a big inky paw-print, much to Will's dismay\nHe scurried away to the wild, wild west\nPut a nut in a six-shooter to put it to the test\nThe sheriff just stared as the squirrel took aim\nAnd history was never, ever quite the same.\n\n(Chorus)\nAnd whoosh! went the world in a blur of green and brown\nHe's a time-traveling squirrel, zipping all over town!\nWith a flick of his tail and a twitch of his nose\nHe's off to the future, or where the past still grows\nHe's seen dinosaurs nibble on giant oak trees\nHe's dodged laser pointers in 2093\nBarnaby's nuts, but not for the reason you'd guess\nHe's got a chronological, beautiful mess!\n\n(Outro)\nSo if you see a squirrel who seems out of place\nWith a look of sheer wonder upon his small face\nMaybe he's just seen a pyramid built\nOr a rocket ship launch at a dizzying tilt\nJust leave him an almond, a walnut will do\nHe might just be passing, on his way through...\n(Guitar strums slow down)\n...On his way back to your... backyard... today.\n(Final, single strum and fade out)"
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = await client.aio.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZV2TY5Pa3Dd"
      },
      "source": [
        "## Send multimodal prompts\n",
        "\n",
        "Gemini is a multimodal model that supports multimodal prompts.\n",
        "\n",
        "You can include any of the following data types from various sources.\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Data type</th>\n",
        "      <th>Source(s)</th>\n",
        "      <th>MIME Type(s)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Text</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code> <code>text/html</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Code</td>\n",
        "      <td>Inline, Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>text/plain</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Document</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>application/pdf</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Image</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td><code>image/jpeg</code> <code>image/png</code> <code>image/webp</code></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Audio</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage</td>\n",
        "      <td>\n",
        "        <code>audio/aac</code> <code>audio/flac</code> <code>audio/mp3</code>\n",
        "        <code>audio/m4a</code> <code>audio/mpeg</code> <code>audio/mpga</code>\n",
        "        <code>audio/mp4</code> <code>audio/opus</code> <code>audio/pcm</code>\n",
        "        <code>audio/wav</code> <code>audio/webm</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Video</td>\n",
        "      <td>Local File, General URL, Google Cloud Storage, YouTube</td>\n",
        "      <td>\n",
        "        <code>video/mp4</code> <code>video/mpeg</code> <code>video/x-flv</code>\n",
        "        <code>video/quicktime</code> <code>video/mpegps</code> <code>video/mpg</code>\n",
        "        <code>video/webm</code> <code>video/wmv</code> <code>video/3gpp</code>\n",
        "      </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "For more examples of multimodal use cases, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4npg1tNTYB9"
      },
      "source": [
        "### Send local image\n",
        "\n",
        "Download an image to local storage from Google Cloud Storage.\n",
        "\n",
        "For this example, we'll use this image of a meal.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\" alt=\"Meal\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4avkv0Z7qUI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92658c8c-fbfc-4e33-b880-5cc235c49963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-29 09:40:48--  https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.251.18.207, 142.250.153.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3140536 (3.0M) [image/png]\n",
            "Saving to: ‘meal.png’\n",
            "\n",
            "meal.png            100%[===================>]   2.99M  4.39MB/s    in 0.7s    \n",
            "\n",
            "2025-08-29 09:40:49 (4.39 MB/s) - ‘meal.png’ saved [3140536/3140536]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/cloud-samples-data/generative-ai/image/meal.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "umhZ61lrSyJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "e878275f-9748-473a-c880-2cfc52ef9b61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is a short and engaging blog post inspired by the image:\n\n### Upgrade Your Lunch Game with This Simple Meal Prep\n\nTired of sad desk lunches and last-minute takeout? It's time to reclaim your midday meal!\n\nThis picture is your new lunch inspiration. Imagine opening your fridge to find these vibrant, pre-portioned glass containers waiting for you. Inside, you've got savory teriyaki chicken, crisp-steamed broccoli, sweet carrots, and a perfect bed of fluffy rice. It’s a balanced, delicious, and satisfying meal that's ready to go when you are.\n\nMeal prepping doesn't have to be complicated. Just an hour on Sunday can set you up for a week of healthy, stress-free lunches that will make your coworkers jealous.\n\n**Ready to get started?**\n*   **Pick a Protein:** Chicken, tofu, or beef work great.\n*   **Load Up on Veggies:** Broccoli, bell peppers, and carrots add color and crunch.\n*   **Choose Your Base:** Rice, quinoa, or noodles are all excellent choices.\n*   **Sauce it Up:** A simple teriyaki or soy-ginger sauce brings it all together.\n\nGive it a try this weekend. Your future self (and your wallet) will thank you"
          },
          "metadata": {}
        }
      ],
      "source": [
        "with open(\"meal.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_bytes(data=image, mime_type=\"image/png\"),\n",
        "        \"Write a short and engaging blog post based on this picture.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7b6170c9255"
      },
      "source": [
        "### Send document from Google Cloud Storage\n",
        "\n",
        "This example document is the paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762), created by researchers from Google and the University of Toronto.\n",
        "\n",
        "Check out this notebook for more examples of document understanding with Gemini:\n",
        "\n",
        "- [Document Processing with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/document-processing/document_processing.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1d58b914d798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "cbe1424c-83b4-4272-a35d-619ec9573125"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ClientError",
          "evalue": "400 FAILED_PRECONDITION. {'error': {'code': 400, 'message': 'Service agents are being provisioned (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents). Service agents are needed to read the Cloud Storage file provided. So please try again in a few minutes.', 'status': 'FAILED_PRECONDITION'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-456162676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = client.models.generate_content(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     contents=[\n\u001b[1;32m      4\u001b[0m         Part.from_uri(\n\u001b[1;32m      5\u001b[0m             \u001b[0mfile_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   6519\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mremaining_remote_calls_afc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6520\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6521\u001b[0;31m       response = self._generate_content(\n\u001b[0m\u001b[1;32m   6522\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6523\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5253\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5255\u001b[0;31m     response = self._api_client.request(\n\u001b[0m\u001b[1;32m   5256\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5257\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mhttp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m     response_body = (\n\u001b[1;32m   1268\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m   async def _async_request_once(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       )\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m       return HttpResponse(\n\u001b[1;32m   1065\u001b[0m           \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mstatus_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: 400 FAILED_PRECONDITION. {'error': {'code': 400, 'message': 'Service agents are being provisioned (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents). Service agents are needed to read the Cloud Storage file provided. So please try again in a few minutes.', 'status': 'FAILED_PRECONDITION'}}"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"gs://cloud-samples-data/generative-ai/pdf/1706.03762v7.pdf\",\n",
        "            mime_type=\"application/pdf\",\n",
        "        ),\n",
        "        \"Summarize the document as a tech oriented individual to a room of techies.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b247a2ee0e38"
      },
      "source": [
        "### Send audio from General URL\n",
        "\n",
        "This example is audio from an episode of the [Kubernetes Podcast](https://kubernetespodcast.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cbe8c9c67ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "18793560-3497-4249-f6a3-2fb79d611de0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This episode of the Kubernetes Podcast from Google, hosted by Abdel Sghiouar and Ofir Nachmani, is a special coverage edition from KubeCon + CloudNativeCon North America 2024. The episode features the latest cloud-native news and interviews with event attendees conducted on the show floor.\n\n**News Highlights:**\n*   **CNCF Graduations:** Both **cert-manager**, a popular certificate manager, and **Dapr** (Distributed Application Runtime) have graduated as CNCF projects.\n*   **Project Milestones:** **Istio** released version 1.24, making its sidecar-less **Ambient Mesh** generally available (GA). **WasmCloud** has joined the CNCF as an incubating project, and **Solo.io** announced it will donate its **Glue API Gateway** to the CNCF.\n*   **Community & Events:** The CNCF announced the **Cloud Native Heroes Challenge**, a bounty program to combat patent trolls. The 2025 event calendar was revealed, including five KubeCons, an Open Source Security Con, and 30 Kubernetes Community Days.\n*   **Certifications & Funding:** Three new CNCF certifications were introduced: Certified Backstage Associate, OpenTelemetry Certified Associate, and Kyverno Certified Associate. However, prices for the CKA, CKS, CKAD, and Linux certified system administrator exams will increase by 10% in 2025. In funding news, **Spectro Cloud** raised $75 million in a Series C round to develop its Kubernetes management platform.\n\n**KubeCon Attendee Interviews:**\nThe main segment features interviews with a diverse group of attendees, including engineers, founders, and architects from companies like Broadcom, Microsoft, Red Hat, Uber, and Polar Signals. They shared their experiences and observations from the conference.\n\n**Hopes for the Event:**\nAttendees came to KubeCon with several goals:\n*   **Connection and Collaboration:** A major theme was the desire for in-person connection, whether reconnecting with fellow contributors, meeting new ones, or having focused face-to-face discussions to resolve project challenges (such as the Kubernetes Long-Term Support working group).\n*   **Learning and Education:** Many sought to deepen their knowledge on specific topics, including the integration of AI with cloud-native technologies, WebAssembly (Wasm), and understanding the intricacies of Kubernetes authorization.\n*   **Inspiration:** Several attendees mentioned seeking the \"six-month boost\" of excitement and motivation that comes from being immersed in the community.\n\n**Key Trends Observed:**\nThe trends at the event closely mirrored the themes of the daily keynotes:\n*   **AI and Machine Learning:** AI was a dominant topic, with a focus on scheduling and managing AI workloads, GPU monitoring, and integrating AI/ML learnings back into the cloud-native ecosystem.\n*   **Security:** Security was a pervasive theme, moving beyond just running workloads to ensuring they are hardened throughout their entire lifecycle. This includes supply chain security, software attestation, and applying security principles to new areas like AI models (e.g., SBOMs for LLMs).\n*   **Community:** The power of the open-source community was a central trend, highlighting collaborative efforts to solve complex problems.\n*   **Service Mesh & Gateways:** There was significant momentum and interest in Istio's Ambient Mesh and the evolution of Envoy-based API gateways."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://traffic.libsyn.com/secure/e780d51f-f115-44a6-8252-aed9216bb521/KPOD242.mp3\",\n",
        "            mime_type=\"audio/mpeg\",\n",
        "        ),\n",
        "        \"Write a summary of this podcast episode.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(\n",
        "        audio_timestamp=True,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D3_oNUTuW2q"
      },
      "source": [
        "### Send video from YouTube URL\n",
        "\n",
        "This example is the YouTube video [Google — 25 Years in Search: The Most Searched](https://www.youtube.com/watch?v=3KtWfp0UopM).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "l7-w8G_2wAOw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f04033e6-ca60-4582-c358-76de38f5a3b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Of course!\n\nThe Harry Potter segment appears at **00:57** in the video, featuring clips of Professor Snape and Hagrid with the text \"the most searched cast.\""
          },
          "metadata": {}
        }
      ],
      "source": [
        "video = Part.from_uri(\n",
        "    file_uri=\"https://www.youtube.com/watch?v=3KtWfp0UopM\",\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        video,\n",
        "        \"At what point in the video is Harry Potter shown?\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df8013cfa7f7"
      },
      "source": [
        "### Send web page\n",
        "\n",
        "This example is from the [Generative AI on Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs).\n",
        "\n",
        "**NOTE:** The URL must be publicly accessible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "337793322c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "a4f06e2c-ecc4-43a5-898d-69bf3b57f50b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the HTML provided, here is a summary of the documentation for \"Generative AI on Vertex AI\":\n\nThis documentation serves as a central hub for Google Cloud's **Generative AI on Vertex AI**, a platform for building, deploying, and managing enterprise-grade generative AI applications and agents.\n\nThe key value propositions of the platform are:\n*   **Enterprise-Ready:** It offers robust security, data privacy, low latency, and enterprise-grade controls.\n*   **State-of-the-Art Models:** Provides access to Google's advanced models like Gemini 2.5, which features a 2 million token context window, multimodality, and advanced reasoning (\"Thinking\") capabilities.\n*   **Open and Flexible:** Through the **Vertex AI Model Garden**, users can access over 200 models, including Google's proprietary models (Gemini, Imagen, Veo) and popular third-party models from Anthropic (Claude), Meta (Llama), and Mistral AI.\n*   **Comprehensive Tooling:** It includes a full suite of tools for the entire AI lifecycle, from building and testing to deploying and monitoring.\n\n**Key Capabilities Highlighted:**\n*   **Agent Builder:** A suite of tools for creating and deploying AI agents.\n*   **Grounding:** Enables models to provide more accurate and up-to-date responses by connecting them to real-time data from Google Search, Google Maps, or private data sources.\n*   **Multimodality:** The platform supports various data types, including text, images, video, and audio for both input and output. This includes image generation with **Imagen** and video generation with **Veo**.\n*   **Tuning and Embeddings:** Users can fine-tune models for specific tasks and generate text or multimodal embeddings for applications like search, classification, and clustering.\n*   **Evaluation Services:** Provides tools to evaluate and benchmark the performance of generative models and applications.\n\n**Getting Started Resources:**\nThe page provides several entry points for users:\n*   **For Developers:** Quickstarts and SDKs are available for Python, Java, Node.js, and Go. It also provides links to Jupyter notebooks (runnable in Colab, Colab Enterprise, or Vertex AI Workbench) that demonstrate various use cases and best practices for prompt design.\n*   **For All Users:** The **Vertex AI Studio Prompt Gallery** allows for code-free experimentation with prompts and models."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=\"https://cloud.google.com/vertex-ai/generative-ai/docs\",\n",
        "            mime_type=\"text/html\",\n",
        "        ),\n",
        "        \"Write a summary of this documentation.\",\n",
        "    ],\n",
        "    config=GenerateContentConfig(thinking_config=thinking_config),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVlo0mWuZGkQ"
      },
      "source": [
        "## Control generated output\n",
        "\n",
        "[Controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field.\n",
        "\n",
        "The response schema is specified in the `response_schema` parameter in `config`, and the model output will strictly follow that schema.\n",
        "\n",
        "You can provide the schemas as [Pydantic](https://docs.pydantic.dev/) models or a [JSON](https://www.json.org/json-en.html) string and the model will respond as JSON or an [Enum](https://docs.python.org/3/library/enum.html) depending on the value set in `response_mime_type`.\n",
        "\n",
        "For more examples of controlled generation, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OjSgf2cDN_bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34186a0c-2264-4fa7-82b7-16ac8dd4deec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Recipe 1\",\n",
            "  \"description\": \"Description 1\",\n",
            "  \"ingredients\": [\n",
            "    \"Ingredient 1\",\n",
            "    \"Ingredient 2\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "    name: str\n",
        "    description: str\n",
        "    ingredients: list[str]\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=Recipe,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKai5CP_PGQF"
      },
      "source": [
        "You can either parse the response string as JSON, or use the `parsed` field to get the response as an object or dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeyDWbnxO-on"
      },
      "outputs": [],
      "source": [
        "parsed_response: Recipe = response.parsed\n",
        "print(parsed_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSLPrvlvXOc"
      },
      "source": [
        "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
        "\n",
        "- `enum`\n",
        "- `items`\n",
        "- `maxItems`\n",
        "- `nullable`\n",
        "- `properties`\n",
        "- `required`\n",
        "\n",
        "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7duWOq3vMmS"
      },
      "outputs": [],
      "source": [
        "response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"ARRAY\",\n",
        "        \"items\": {\n",
        "            \"type\": \"OBJECT\",\n",
        "            \"properties\": {\n",
        "                \"rating\": {\"type\": \"INTEGER\"},\n",
        "                \"flavor\": {\"type\": \"STRING\"},\n",
        "                \"sentiment\": {\n",
        "                    \"type\": \"STRING\",\n",
        "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
        "                },\n",
        "                \"explanation\": {\"type\": \"STRING\"},\n",
        "            },\n",
        "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "  Analyze the following product reviews, output the sentiment classification, and give an explanation.\n",
        "\n",
        "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
        "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV1dR-QlTKRs"
      },
      "source": [
        "## Count tokens and compute tokens\n",
        "\n",
        "You can use the `count_tokens()` method to calculate the number of input tokens before sending a request to the Gemini API.\n",
        "\n",
        "For more information, refer to [list and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syx-fwLkV1j-"
      },
      "source": [
        "### Count tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhNElguLRRNK"
      },
      "outputs": [],
      "source": [
        "response = client.models.count_tokens(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What's the highest mountain in Africa?\",\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsP0vXOY7hg"
      },
      "source": [
        "## Search as a tool (Grounding)\n",
        "\n",
        "[Grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you connect real-world data to the Gemini model.\n",
        "\n",
        "By grounding model responses in Google Search results, the model can access information at runtime that goes beyond its training data which can produce more accurate, up-to-date, and relevant responses.\n",
        "\n",
        "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search.\n",
        "\n",
        "For more examples of Grounding, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_M_4RRBdO_3"
      },
      "source": [
        "### Google Search\n",
        "\n",
        "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeR09J3AZT4U"
      },
      "outputs": [],
      "source": [
        "google_search_tool = Tool(google_search=GoogleSearch())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the current temperature in Austin, TX?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[google_search_tool],\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))\n",
        "\n",
        "print(response.candidates[0].grounding_metadata)\n",
        "\n",
        "HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0pb-Kh1xEHU"
      },
      "source": [
        "## Function calling\n",
        "\n",
        "[Function Calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling) in Gemini lets developers create a description of a function in their code, then pass that description to a language model in a request.\n",
        "\n",
        "You can submit a Python function for automatic function calling, which will run the function and return the output in natural language generated by Gemini.\n",
        "\n",
        "You can also submit an [OpenAPI Specification](https://www.openapis.org/) which will respond with the name of a function that matches the description and the arguments to call it with.\n",
        "\n",
        "For more examples of Function calling with Gemini, check out this notebook: [Intro to Function Calling with Gemini](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSUWWlrrlR-D"
      },
      "source": [
        "### Python Function (Automatic Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRR8HZhLlR-E"
      },
      "outputs": [],
      "source": [
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"Example method. Returns the current weather.\n",
        "\n",
        "    Args:\n",
        "        location: The city and state, e.g. San Francisco, CA\n",
        "    \"\"\"\n",
        "    weather_map: dict[str, str] = {\n",
        "        \"Boston, MA\": \"snowing\",\n",
        "        \"San Francisco, CA\": \"foggy\",\n",
        "        \"Seattle, WA\": \"raining\",\n",
        "        \"Austin, TX\": \"hot\",\n",
        "        \"Chicago, IL\": \"windy\",\n",
        "    }\n",
        "    return weather_map.get(location, \"unknown\")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the weather like in San Francisco?\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[get_current_weather],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4syyLEClGcn"
      },
      "source": [
        "### OpenAPI Specification (Manual Function Calling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BDQPwgcxRN3"
      },
      "outputs": [],
      "source": [
        "get_destination = FunctionDeclaration(\n",
        "    name=\"get_destination\",\n",
        "    description=\"Get the destination that the user wants to go to\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"destination\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"description\": \"Destination that the user wants to go to\",\n",
        "            },\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "destination_tool = Tool(\n",
        "    function_declarations=[get_destination],\n",
        ")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"I'd like to travel to Paris.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[destination_tool],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.function_calls[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhDs2X3o0neK"
      },
      "source": [
        "## Code Execution\n",
        "\n",
        "The Gemini API [code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output. You can use this code execution capability to build applications that benefit from code-based reasoning and that produce text output. For example, you could use code execution in an application that solves equations or processes text.\n",
        "\n",
        "The Gemini API provides code execution as a tool, similar to function calling.\n",
        "After you add code execution as a tool, the model decides when to use it.\n",
        "\n",
        "For more examples of Code Execution, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/code-execution/intro_code_execution.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W-3c7sy0nyz"
      },
      "outputs": [],
      "source": [
        "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\",\n",
        "    config=GenerateContentConfig(\n",
        "        tools=[code_execution_tool],\n",
        "        temperature=0,\n",
        "        thinking_config=thinking_config,\n",
        "    ),\n",
        ")\n",
        "\n",
        "display(\n",
        "    Markdown(\n",
        "        f\"\"\"\n",
        "## Code\n",
        "\n",
        "```py\n",
        "{response.executable_code}\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "```\n",
        "{response.code_execution_result}\n",
        "```\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwiONFdVHw5"
      },
      "source": [
        "## What's next\n",
        "\n",
        "- See the [Google Gen AI SDK reference docs](https://googleapis.github.io/python-genai/).\n",
        "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
        "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_2_5_pro.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}